{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Software\\Anaconda\\envs\\tf_env_py311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "from PIL import Image\n",
    "from deepface import DeepFace\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224, 224)\n",
    "my_images = glob.glob(\"my_images2/*\")\n",
    "threshold = 0.85\n",
    "embeddings_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_embeddings():\n",
    "    image_features = []\n",
    "\n",
    "    for img_path in my_images:\n",
    "        try:\n",
    "            embedding = DeepFace.represent(img_path, model_name=\"Facenet\", enforce_detection=False, align=False)\n",
    "            embedding = embedding[0][\"embedding\"]\n",
    "            embeddings_dict[img_path] = embedding\n",
    "            image_features.append(embedding)\n",
    "        except:\n",
    "            print(f\"No face detected in {img_path}\")\n",
    "\n",
    "    image_features = np.array(image_features)\n",
    "    return image_features\n",
    "\n",
    "embeddings = my_embeddings()\n",
    "np.save(\"face_embeddings.npy\", embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_embedding(img):\n",
    "    try:\n",
    "        similarities = []\n",
    "        embedding = DeepFace.represent(img, model_name=\"Facenet\", enforce_detection=False, align=False)\n",
    "        embedding = embedding[0]\n",
    "        face = embedding[\"facial_area\"]\n",
    "        x, y, w, h = face[\"x\"], face[\"y\"], face[\"w\"], face[\"h\"]\n",
    "        for em in embeddings:\n",
    "            similarity = 1 - cosine(em, embedding[\"embedding\"])\n",
    "            similarities.append(similarity)\n",
    "        max_similarity = max(similarities)\n",
    "        print(max_similarity)\n",
    "        return embedding[\"embedding\"], True, (x, y, w, h), max_similarity\n",
    "    except:\n",
    "        print(\"No face detected!\")\n",
    "        return None, False, None, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face detected!\n",
      "This is not you.\n"
     ]
    }
   ],
   "source": [
    "test_img = cv2.imread(\"alaa.jpg\")\n",
    "embedding, result, face_info, max_similarity = image_embedding(test_img)\n",
    "print(\"This is you, Abolfazl!\") if max_similarity > threshold else print(\"This is not you.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_show(frame):\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(rgb_frame)\n",
    "    IPython.display.display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687619764499651\n",
      "0.6793090768401711\n",
      "0.7291363577754543\n",
      "0.7460572373568811\n",
      "0.7667496635586838\n",
      "0.7238959616667524\n",
      "0.8225544507899683\n",
      "0.8037921442285368\n",
      "0.8097644607336771\n",
      "0.8184377248694868\n",
      "0.8367154971918852\n",
      "0.748236623994686\n",
      "0.7218193036540572\n",
      "0.787787682920211\n",
      "0.8470773118325301\n",
      "0.8030096191318911\n",
      "0.8231294414969631\n",
      "0.844908574235961\n",
      "0.8344147818456364\n",
      "0.8071268478616296\n",
      "0.8377033077125927\n",
      "0.7858601763197095\n",
      "0.7993023879816774\n",
      "0.8574245081044094\n",
      "0.8578619889405539\n",
      "0.8508664312335255\n",
      "0.802111571605145\n",
      "0.8163364554513451\n",
      "0.6814800359999152\n",
      "0.7121970911036539\n",
      "0.7016848008389374\n",
      "0.6224641590679197\n",
      "0.6955805057285411\n",
      "0.7452122508666569\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Abolfazl Detector\")\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "frame_counter = 0\n",
    "skip_threshold = 20\n",
    "display_duration = 1.5\n",
    "\n",
    "last_detection_time = 0\n",
    "last_result = None\n",
    "last_face_info = None\n",
    "last_max_similarity = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "        break\n",
    "\n",
    "    frame_counter += 1\n",
    "\n",
    "    if frame_counter % skip_threshold == 0:\n",
    "        embedding, result, face_info, max_similarity = image_embedding(frame)\n",
    "\n",
    "        if embedding is not None:\n",
    "            last_detection_time = time.time()\n",
    "            last_result = result\n",
    "            last_face_info = face_info\n",
    "            last_max_similarity = max_similarity\n",
    "\n",
    "    if last_result is not None and time.time() - last_detection_time < display_duration:\n",
    "        x, y, w, h = last_face_info\n",
    "        sm = f\"%{max_similarity * 100}\"[:6]\n",
    "        text = \"This is not you.\"\n",
    "\n",
    "        (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "        (sm_width, sm_height), _ = cv2.getTextSize(sm, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "\n",
    "        x_text = x\n",
    "        y_text = y - 10\n",
    "        x_sm = x_text + (text_width - sm_width) // 2\n",
    "        y_sm = y_text - 25\n",
    "\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "        if last_max_similarity > threshold:\n",
    "            text = \"This is you, Abolfazl!\"\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "        if last_result:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, text, (x_text, y_text), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.8, color, 2, cv2.LINE_AA)\n",
    "            cv2.putText(frame, sm, (x_sm, y_sm), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        0.8, color, 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Abolfazl Detector\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
